{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO_2eKV45185"
      },
      "source": [
        "# import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLB33UoEpkOm",
        "outputId": "517bc2f0-f8af-4b66-d51f-25d488a78189"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import string\n",
        "\n",
        "import nltk\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "\n",
        "from nltk import pos_tag\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,classification_report\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b64YMTR58Rl"
      },
      "source": [
        "# import the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "voOetICrp-Mn",
        "outputId": "97f21d80-bc4e-4d74-f70b-a44cb01b0e08"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Now I am getting angry and I want my damn pho.</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Honeslty it didn't taste THAT fresh.</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The potatoes were like rubber and you could te...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The fries were great too.</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A great touch.</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Service was very prompt.</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Would not go back.</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>The cashier had no care what so ever on what I...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>I tried the Cape Cod ravoli, chicken, with cra...</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I was disgusted because I was pretty sure that...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I was shocked because no signs indicate cash o...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Highly recommended.</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Waitress was a little slow in service.</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>This place is not worth your time, let alone V...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>did not like at all.</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Review Liked\n",
              "0                            Wow... Loved this place.   Yes\n",
              "1                                  Crust is not good.    No\n",
              "2           Not tasty and the texture was just nasty.    No\n",
              "3   Stopped by during the late May bank holiday of...   Yes\n",
              "4   The selection on the menu was great and so wer...   Yes\n",
              "5      Now I am getting angry and I want my damn pho.    No\n",
              "6                Honeslty it didn't taste THAT fresh.    No\n",
              "7   The potatoes were like rubber and you could te...    No\n",
              "8                           The fries were great too.   Yes\n",
              "9                                      A great touch.   Yes\n",
              "10                           Service was very prompt.   Yes\n",
              "11                                 Would not go back.    No\n",
              "12  The cashier had no care what so ever on what I...    No\n",
              "13  I tried the Cape Cod ravoli, chicken, with cra...   Yes\n",
              "14  I was disgusted because I was pretty sure that...    No\n",
              "15  I was shocked because no signs indicate cash o...    No\n",
              "16                                Highly recommended.   Yes\n",
              "17             Waitress was a little slow in service.    No\n",
              "18  This place is not worth your time, let alone V...    No\n",
              "19                               did not like at all.    No"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data= pd.read_csv(\"Restaurant_Reviews.csv\")\n",
        "data.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmfAZMj6qLUP",
        "outputId": "b5005b82-d5f3-4a9b-c2f3-4ee10b36eca2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2220, 2)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "01gDr59BqlYd",
        "outputId": "dd9fc258-a8a2-467e-994b-ffdcc4b0f062"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Review</th>\n",
              "      <td>2220</td>\n",
              "      <td>1610</td>\n",
              "      <td>The restaurant had clean and well-maintained f...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Liked</th>\n",
              "      <td>2220</td>\n",
              "      <td>2</td>\n",
              "      <td>No</td>\n",
              "      <td>1119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       count unique                                                top  freq\n",
              "Review  2220   1610  The restaurant had clean and well-maintained f...    31\n",
              "Liked   2220      2                                                 No  1119"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "Ig8mXqbDqs5q",
        "outputId": "515a98d9-49dd-45b8-ef92-187e2f817eae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_28548\\4275275759.py:3: FutureWarning: The behavior of pd.concat with len(keys) != len(objs) is deprecated. In a future version this will raise instead of truncating to the smaller of the two sequences\n",
            "  missing_data=pd.concat([count,percentage],axis=1,keys=['count,percentage'])\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count,percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Review</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Liked</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        count,percentage\n",
              "Review                 0\n",
              "Liked                  0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count= data.isnull().sum().sort_values(ascending=False)\n",
        "percentage= ((data.isnull().sum()/len(data)*100)).sort_values(ascending=False)\n",
        "missing_data=pd.concat([count,percentage],axis=1,keys=['count,percentage'])\n",
        "missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGmf6ylK5umw"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dew5T884sDT6",
        "outputId": "15d545d5-570e-41f8-c56f-20414aee894f"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    # original of the words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    # remove stop words\n",
        "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "    # Remove punctuation\n",
        "    tokens = [word for word in tokens if word not in string.punctuation]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "data['Review'] = data['Review'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhCMWaQR6Gm-"
      },
      "source": [
        "# Feature Extraction (Bag of Words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-HlNwuPw3Aii"
      },
      "outputs": [],
      "source": [
        "# convert the data to vectors of the word and the number of his appearence\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# feature column\n",
        "x = vectorizer.fit_transform(data['Review'])\n",
        "\n",
        "# target column\n",
        "y = data['Liked']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DnV0x0u6Mf1"
      },
      "source": [
        "# choose model and train it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-j99lCCzzhwu"
      },
      "outputs": [],
      "source": [
        "# spilt the data to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=0)\n",
        "\n",
        "# train the data by using RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# prediction\n",
        "y_pred = classifier.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBri4-YT6Rt_"
      },
      "source": [
        "# evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NeoeEqO4bb9",
        "outputId": "928277c1-1cf2-453f-c708-4bbe6b332aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 88.96 %\n",
            "Precision: 93.75 %\n",
            "Recall: 82.95 %\n",
            "F1 Score: 88.02 %\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.85      0.95      0.90       227\n",
            "         Yes       0.94      0.83      0.88       217\n",
            "\n",
            "    accuracy                           0.89       444\n",
            "   macro avg       0.90      0.89      0.89       444\n",
            "weighted avg       0.89      0.89      0.89       444\n",
            "\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label='Yes')\n",
        "recall = recall_score(y_test, y_pred, pos_label='Yes')\n",
        "f1 = f1_score(y_test, y_pred, pos_label='Yes')\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy*100:.2f} %')\n",
        "print(f'Precision: {precision*100:.2f} %')\n",
        "print(f'Recall: {recall*100:.2f} %')\n",
        "print(f'F1 Score: {f1*100:.2f} %')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted label: ['Yes']\n"
          ]
        }
      ],
      "source": [
        "new_record = preprocess_text(\"i am happy\")\n",
        "numerical_record = vectorizer.transform([new_record])\n",
        "prediction = classifier.predict(numerical_record)\n",
        "print(\"Predicted label:\", prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def predict_sentiment(review):\n",
        "    preprocessed_review = preprocess_text(review)\n",
        "    numerical_review = vectorizer.transform([preprocessed_review])\n",
        "    prediction = classifier.predict(numerical_review)\n",
        "    return prediction[0]\n",
        "input_text = gr.Textbox(lines=5, label=\"Enter a review\")  # You can use Textbox for multiline input\n",
        "output_label = gr.Text(label=\"Predicted Sentiment\")\n",
        "demo= gr.Interface(fn=predict_sentiment, inputs=input_text, outputs=output_label)\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
